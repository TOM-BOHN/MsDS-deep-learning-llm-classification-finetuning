{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwlZkcWkuGMD"
      },
      "source": [
        "# Deep Learning: LLM: Classification Finetuning\n",
        "**Thomas Bohn**   --   **2025-09-30**\n",
        "\n",
        "{{xxxxx}}  \n",
        "\n",
        "--  [Main Report](https://github.com/TOM-BOHN/MsDS-deep-learning-llm-classification-finetuning/blob/main/deep-learning-llm-classification-finetuning.ipynb)  --  [Github Repo](https://github.com/TOM-BOHN/MsDS-deep-learning-llm-classification-finetuning)  --  [Presentation Slides](xxx)  --  [Presentation Video](xxx) --  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07lWDJH6vAuV"
      },
      "source": [
        "# 1.&nbsp;Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHhIXdBPvCDs"
      },
      "source": [
        "**Problem Statement**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Why is it Important?**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Limitations of Existing Solutions**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Contribution**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**DataSet**\n",
        "\n",
        "{{xxxxx}}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview of Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "{{xxxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detect Environment\n",
        "\n",
        "Determine if the notebook is running in Colab or Kaggle. Then change how the notebook behaves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect Environment\n",
        "import os\n",
        "gIS_COLAB = 'COLAB_GPU' in os.environ or 'COLAB_TPU' in os.environ or 'COLAB_CPU' in os.environ\n",
        "gIS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
        "print(\"Is Kaggle?\", gIS_KAGGLE, \" | \", \"Is Colab?\", gIS_COLAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add Colab Only Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the necessary packages\n",
        "import os\n",
        "if gIS_COLAB:\n",
        "    # Install Colab Specific Tooling\n",
        "    from google.colab import userdata\n",
        "    from google.colab import files\n",
        "\n",
        "    # Mount the Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Install the necessary packages\n",
        "    !pip install -q tensorflow\n",
        "    !pip install -q kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Add Kaggle Only Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the necessary packages\n",
        "if gIS_KAGGLE:\n",
        "    from kaggle_datasets import KaggleDatasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9augt6L_Wnb"
      },
      "source": [
        "## Common Python Libraries\n",
        "\n",
        "The following python libraries are used in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "pjoVn_82_Rya",
        "outputId": "0c19792c-ae58-4e05-89bb-ac5327391e69"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (0.5.13)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words) (0.6.2)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.10/dist-packages (0.8.1)\n"
          ]
        }
      ],
      "source": [
        "# File system manangement\n",
        "import time, datetime, psutil, os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Install text storage and manipulation\n",
        "import re\n",
        "import json\n",
        "import pickle\n",
        "import textwrap\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "##################################\n",
        "\n",
        "# Plotting and visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "# Train-test split and cross validation\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "\n",
        "# Model evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Import Tensor Flow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_nlp\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, History\n",
        "\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
        "\n",
        "##################################\n",
        "\n",
        "print(f'Keras: {keras.__version__}')\n",
        "print(f'KerasNLP: {keras_nlp.__version__}')\n",
        "print(f'Tensorflow: {tf.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to TPUs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TPU (Tensor Processing Unit) Setup for Accelerated Training\n",
        "# This code attempts to connect to Google's TPU infrastructure for faster model training\n",
        "# TPUs are specialized hardware designed specifically for machine learning workloads\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('✅ TPU found:', tpu.master())\n",
        "except:\n",
        "    print(\"❌ No TPU found. Falling back to CPU/GPU.\")\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    # Connect to the TPU cluster.\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    # Initialize the TPU system for use\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    # Create a TPU distribution strategy for multi-core TPU usage\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "else:\n",
        "    # Use the default strategy for CPU/GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "# Print the number of replicas (cores) available for parallel processing\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "\n",
        "# Set up automatic tuning for data pipeline performance optimization\n",
        "# AUTOTUNE allows TensorFlow to automatically determine the optimal number of parallel calls\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Print TensorFlow version for reference\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to GPUs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(tf.test.gpu_device_name())\n",
        "\n",
        "# Configure GPU memory growth (prevents OOM errors)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y39B3sJjvTD1"
      },
      "source": [
        "## Global Variables\n",
        "\n",
        "The following are global variables referenced in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vfjyMW6K_SS-"
      },
      "outputs": [],
      "source": [
        "# Recording the starting time, complemented with a stopping time check in the end to compute process runtime\n",
        "start = time.time()\n",
        "\n",
        "# Class representing the OS process and having memory_info() method to compute process memory usage\n",
        "process = psutil.Process(os.getpid())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uLiPgQzL-Oiu",
        "outputId": "1daa3a4c-d833-4341-a5f4-e588be3b7163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Level of Detail for functions is set to: 2\n"
          ]
        }
      ],
      "source": [
        "# Global Debug flag used to turn on and off more chatty blocks of code\n",
        "gDEBUG = True\n",
        "print('Debug is set to:', gDEBUG)\n",
        "# Global Level of Detail of table stats and details\n",
        "gLOD = 2\n",
        "print('Level of Detail for functions is set to:', gLOD)\n",
        "\n",
        "# Use environment global variables\n",
        "gIS_COLAB = gIS_COLAB\n",
        "gIS_KAGGLE = gIS_KAGGLE\n",
        "print(\"Is Kaggle?\", gIS_KAGGLE, \" | \", \"Is Colab?\", gIS_COLAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    seed = 27  # Random seed\n",
        "    preset = \"deberta_v3_extra_small_en\" # Name of pretrained models\n",
        "    sequence_length = 512  # Input sequence length\n",
        "    epochs = 5 # Training epochs\n",
        "    batch_size = 16  # Batch size\n",
        "    scheduler = 'cosine'  # Learning rate scheduler\n",
        "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
        "    name2label = {v:k for k, v in label2name.items()}\n",
        "    class_labels = list(label2name.keys())\n",
        "    class_names = list(label2name.values())\n",
        "\n",
        "# Sets value for random seed to produce similar result in each run.\n",
        "keras.utils.set_random_seed(CFG.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnEP1IbB-1dF"
      },
      "source": [
        "# 2.&nbsp;Data Source\n",
        "\n",
        "In this section, the code loads the dataset from Google Drive.\n",
        "\n",
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E54ZVhqGH0o1"
      },
      "source": [
        "## Import the Data (Kaggle or Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "s47OY0wa-9VR",
        "outputId": "73c66d41-1e90-4c72-dd74-eecd25769ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#print('os.environ: ', os.environ)\n",
        "\n",
        "if 'KAGGLE_KERNEL_RUN_TYPE' in os.environ:\n",
        "    print(\"Detected Kaggle environment - using Kaggle datasets\")\n",
        "elif 'COLAB_GPU' in os.environ or 'COLAB_TPU' in os.environ or 'COLAB_CPU' in os.environ:\n",
        "    print(\"Detected Google Colab environment - using local datasets\")\n",
        "else:\n",
        "    print(\"YIKES! I don't know where I am !!!!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr1LwEFwAUTh"
      },
      "outputs": [],
      "source": [
        "# Environment Detection and Dataset Loading\n",
        "# Detect whether we're running in Kaggle or Google Colab and load datasets accordingly\n",
        "\n",
        "if gIS_KAGGLE:\n",
        "    print(\"Detected Kaggle environment - using Kaggle datasets\")\n",
        "\n",
        "    # Dataset Path Configuration for Kaggle Environment\n",
        "    # This allows access to the competition datasets stored in Kaggle's cloud storage\n",
        "    GCS_PATH = '/kaggle/input/llm-classification-finetuning'\n",
        "\n",
        "    # Load Dataset for train\n",
        "    train_path = os.path.join(GCS_PATH, 'train.csv')\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    print('Train Dataset Size:', len(train_df))\n",
        "\n",
        "    # Load Dataset for test\n",
        "    test_path = os.path.join(GCS_PATH, 'test.csv')\n",
        "    test_df = pd.read_csv(test_path)\n",
        "    print('Test Dataset Size:', len(test_df))\n",
        "\n",
        "elif gIS_COLAB:\n",
        "    print(\"Detected Google Colab environment - using local datasets\")\n",
        "\n",
        "    # Define the source of the zipped data files\n",
        "    target_file = 'llm-classification-finetuning.zip'\n",
        "    source_path_root = '/content/drive/MyDrive/[1.4] MsDS Class Files/-- DTSA 5511 Deep Learning/data'\n",
        "    destination_path_root = '/content'\n",
        "\n",
        "    # Copy the files to the runtime\n",
        "    shutil.copy(source_path_root + '/' + target_file, destination_path_root + '/')\n",
        "\n",
        "    # Display the files in the destination directory\n",
        "    print('Files in destination directory:', os.listdir(destination_path_root + '/'))\n",
        "\n",
        "    # Unzip the files (this is slow)\n",
        "    zip_file_path = destination_path_root + '/' + target_file\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        # Extract all the contents into the specified folder\n",
        "        zip_ref.extractall(destination_path_root + '/' + 'llm-classification-finetuning')\n",
        "\n",
        "    print('Dataset extraction completed')\n",
        "\n",
        "    # Dataset Path Configuration for Google Colab Environment\n",
        "    # Set up local file paths for the extracted dataset files\n",
        "    COLAB_DATA_PATH = '/content/llm-classification-finetuning'\n",
        "\n",
        "    # Load Dataset for train\n",
        "    train_path = os.path.join(COLAB_DATA_PATH, 'train.csv')\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    print('Train Dataset Size:', len(train_df))\n",
        "    \n",
        "    # Load Dataset for test\n",
        "    test_path = os.path.join(COLAB_DATA_PATH, 'test.csv')\n",
        "    test_df = pd.read_csv(test_path)\n",
        "    print('Test Dataset Size:', len(test_df))\n",
        "\n",
        "else:\n",
        "    print(\"YIKES! I don't know where I am !!!!!!\")\n",
        "\n",
        "# Verify the datasets are loaded correctly\n",
        "if len(train_df) > 0:\n",
        "    print(f\"Successfully loaded {len(train_df)} training records\")\n",
        "else:\n",
        "    print(\"No training files found. Check the dataset path.\")\n",
        "\n",
        "if len(test_df) > 0:\n",
        "    print(f\"Successfully loaded {len(test_df)} test records\")\n",
        "else:\n",
        "    print(\"No test files found. Check the dataset path.\")\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JAv-COuvtIa"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SDhEs0dwHtb"
      },
      "source": [
        "## Address Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwlHSmjPFHl4"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV3brMgOMPMc"
      },
      "source": [
        "## Data Scoping Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTPr0Xs6Hv8t"
      },
      "source": [
        "## Scope the Label and Text for Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BtBwi2SKW2N"
      },
      "source": [
        "# 3.&nbsp;Exploratory Data Analysis (EDA)\n",
        "\n",
        "The EDA phase focuses on understanding the dataset, including data distribution and label counts. Various functions are used to inspect the structure of the dataset, visualize the label distribution, and assess the text length and word count of the documentation. The data is found to be somewhat imbalanced across categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcwHYK4SI7wY"
      },
      "source": [
        "## EDA Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bO3CvKfI_eC"
      },
      "source": [
        "## EDA Analysis: Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKqQq5X1yCDw"
      },
      "source": [
        "## EDA Analysis: Text Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SnbCeUGydTo"
      },
      "source": [
        "## EDA Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpqY9vM_yefS"
      },
      "source": [
        "ADD HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_4RFPD2fkeh"
      },
      "source": [
        "# 4.&nbsp;Train-Validation-Test Split\n",
        "\n",
        "Split the dataset into training, validation, and test sets. Use tratified splitting to ensure that the class distribution remains consistent across these sets. The distribution of records across the labels is visualized to ensure a balanced split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ctkj7jNx4B"
      },
      "source": [
        "## Test Split Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT6-MV_PN1CC"
      },
      "source": [
        "## Test Split Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3xCg6WhgqXI"
      },
      "source": [
        "# 5.&nbsp;Data Cleansing & Text Normalization\n",
        "\n",
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap4Hw4S8Jd3E"
      },
      "source": [
        "## Core Normalization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gZaDQqdJoe_"
      },
      "source": [
        "## Apply Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm-_DGFFmuSv"
      },
      "source": [
        "# 6.&nbsp;Feature Engineering with TF-IDF\n",
        "\n",
        "The TfidfVectorizer from scikit-learn is used to convert the text documents into numerical features. The vectorizer transforms the collection of documents into a matrix of token counts, which is then normalized using the Term Frequency-Inverse Document Frequency (TF-IDF) transformation. This matrix representation of the text data serves as input to the machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWadgSEmJy8W"
      },
      "source": [
        "## TF_IDF Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whSsaEBx0a_L"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrJc1ZCi0IVf"
      },
      "source": [
        "# 7.&nbsp; Baseline Models: Supervised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO9FkdrHJ5US"
      },
      "source": [
        "## Model Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eMVteAb01Vs"
      },
      "source": [
        "## Build, Train, and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0vP9xMCnepL"
      },
      "source": [
        "# 8.&nbsp; Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pYPbH5L1bjZ"
      },
      "source": [
        "## Tuning Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxev-Ul1pX9"
      },
      "source": [
        "## Execute Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qsNOvyUoeyj"
      },
      "source": [
        "# 9.&nbsp;Final Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka8gqTlWKIl_"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II9qX_tf2LSL"
      },
      "source": [
        "## Train the Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DueXwork2PiL"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CQ4nuAfqRJA"
      },
      "source": [
        "## Explore Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSKrlnc92lEz"
      },
      "source": [
        "# 10.&nbsp;Scale the Auto-Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZDLjLP53aIq"
      },
      "source": [
        "## Auto-Classifier Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad5blW7Os2iX"
      },
      "source": [
        "## Rerun Process for L1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhOtlzh0jGGe"
      },
      "source": [
        "## Rerun Process for L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWv340Xx265l"
      },
      "source": [
        "# 11.&nbsp; Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuHSlWe-O-br"
      },
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNzNW_nH37_9"
      },
      "source": [
        "## Results Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Result Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YlcWEw_8Bp-"
      },
      "source": [
        "\n",
        "**Baseline Results**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Hyperparameter Tuning Results**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Best Model Results**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Best Model Performance**\n",
        "\n",
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEQfc7PI38Tq"
      },
      "source": [
        "## Model Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql8QLBc2LoEy"
      },
      "source": [
        "### Model Comparisons and Findings\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Baseline Results\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Hyperparameter Tuning\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Best Model Results\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Performance Breakdown (Best Model)\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlXB6itm4D4r"
      },
      "source": [
        "## Concluding Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGbGMDoNOr-w"
      },
      "source": [
        "## Patterns and Conclusions Across the Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8ofvfgBOsLZ"
      },
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb2X9yUX4FOn"
      },
      "source": [
        "# 12.&nbsp; References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq8tcmLa4FXR"
      },
      "source": [
        "**Kaggle Competition**\n",
        "\n",
        "- [1] Wei-lin Chiang, Lianmin Zheng, Lisa Dunlap, Joseph E. Gonzalez, Ion Stoica, Paul Mooney, Sohier Dane, Addison Howard, and Nate Keating. LLM Classification Finetuning. https://kaggle.com/competitions/llm-classification-finetuning, 2024. Kaggle.\n",
        "\n",
        "**Documentation and References**\n",
        "\n",
        "- [2] Addison Howard. LMSYS: KerasNLP Starter. https://www.kaggle.com/code/addisonhoward/lmsys-kerasnlp-starter, 2024. Kaggle.\n",
        "- [3] tt195361. LMSYS: Keras NLP Starter with some changes. https://www.kaggle.com/code/tt195361/lmsys-keras-nlp-starter-with-some-changes#Data-Analysis, 2025. Kaggle.\n",
        "- [4] Adel Anseur. LLM Classification finetuning DeBERTA. https://www.kaggle.com/code/adelanseur/llm-classification-finetuning-deberta  2025. Kaggle.\n",
        "\n",
        "**Prior Work Items Referenced**\n",
        "\n",
        "- [5] Thomas Bohn. deep-learing-gan-monet-painting.ipynb. 2025. https://github.com/TOM-BOHN/MsDS-deep-learing-gan-monet-painting/tree/main\n",
        "- [6] Thomas Bohn. deep-learing-rnn-disaster-tweets.ipynb 2025. https://github.com/TOM-BOHN/MsDS-deep-learing-rnn-disaster-tweets\n",
        "\n",
        "**AI Tools Leveraged**\n",
        "\n",
        "- Cursor.AI was used to aggressively document getting started code that was undocumented in the tutorial.\n",
        "- Cursor.AI was used to support the formatting of markdown tables and text blocks.\n",
        "- Cursor.AI was used to write git commit messages when writing to the repo and tracking checkpoints.\n",
        "- Gemini AI was used to analyze and understand referenced code from other projects and repositories.\n",
        "- Gemini AI was used to debug and resolve errors when running notebooks.\n",
        "- Grammarly was used for spelling and grammar correction during the writing process."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMWZ5mItuBlVRpXzeiXWthd",
      "collapsed_sections": [
        "r9augt6L_Wnb",
        "6BtBwi2SKW2N"
      ],
      "mount_file_id": "1h_D7cL2gGhflQZVfZeEActICb25iEJfa",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
